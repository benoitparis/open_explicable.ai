<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Explainable Machine Learning</title>
    <link>http://replace-this-with-your-hugo-site.com/</link>
    <description>Recent content on Explainable Machine Learning</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 01 Nov 2017 12:28:54 +0100</lastBuildDate>
    <atom:link href="http://replace-this-with-your-hugo-site.com/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Explainable machine learning</title>
      <link>http://replace-this-with-your-hugo-site.com/post/explainable-machine-learning/</link>
      <pubDate>Wed, 01 Nov 2017 12:28:54 +0100</pubDate>
      
      <guid>http://replace-this-with-your-hugo-site.com/post/explainable-machine-learning/</guid>
      <description>&lt;p&gt;While achieving great predictive power, machine learning models can be really opaque for their users; Be it a data science team, a marketing executive, a salesperson, or even the end user.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.darpa.mil/&#34;&gt;DARPA&lt;/a&gt; has recently launched a program aimed just at that: &lt;a href=&#34;https://www.darpa.mil/program/explainable-artificial-intelligence&#34;&gt;Explainable Artificial Intelligence (XAI)&lt;/a&gt;. While DARPA&amp;rsquo;s approach is in specifically targeting black-box models, there is plenty of insights in inspecting the internals of the model at hand.&lt;/p&gt;

&lt;p&gt;The aim of this project is to build support for explorations of model parameters, to provide humans an understanding of decisions taken.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>